\section{Case Study}

The primary motivation for this work is to improve probabilistic forecasts of wind power production, following the framework of \citet{jorgensenSequentialMethodsError2025}. To ensure a direct comparison with their results, we use the same dataset and modeling conditions.

\subsection{Data}

The dataset consists of observed wind-power production and an ensemble of physically based production forecasts for the two Danish electricity bidding zones, DK1 and DK2, each further divided into onshore and offshore wind production.
The two zones differ substantially in geography, installed capacity, and interconnection structure:

\begin{itemize}
    \item DK1 is interconnected with continental Europe.
    \item DK2 is interconnected with the Nordic countries.
\end{itemize}

Each zone exhibits distinct production dynamics, but the time series show clear cross-zone correlation.
Notably, DK1 onshore has by far the largest installed capacity—approximately equal to the other three subzones combined.

A representative example of the full dataset is shown in \cref{caseproduction}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{Results/Graphs/data_example.pdf}
    \caption{Caption}
    \label{casedata}
\end{figure}

\subsubsection{Observed power Production}
\label{case-data-observed}
Observed production data spans the period
2022‑01‑01 00:00:00 to 2024‑10‑12 23:00:00,
obtained from the Danish TSO Energinet, via their open data service
\href{https://www.energidataservice.dk/}{Energi Data Service} \citep{energinetEnergiDataService}.

The data used here is from the dataset for statistical use. This means that data is only available after a considerable wait (days to weeks). As an alternative Energinet also provides a real-time dataset.

A statistical summary of the observed production for all four zones is provided in \cref{tab:data:observation}.

\input{Results/Tables/observations_summary}

\subsubsection{Ensemble forecast}
The dataset also includes ensemble forecasts derived from ECMWF weather forecasts. Forecasts are provided at hourly resolution, and each day’s forecast is issued 12 hours before the target day.

\begin{itemize}
    \item 1 high‑probability ensemble (HPE)
    \item 50 perturbed ensemble members, generated by perturbing the initial conditions of the HPE.
\end{itemize}

Thus, each forecast consists of 51 physically simulated scenarios for each zone.

The weather forecast from the ECMWF is directly converted into of forecasted power production by a proprietary methods. 

Due to the proprietery nature of the neither the provider of, nor the full data can be disclosed 

Some anomalies are present particularly for DK2‑onshore, where forecasts occasionally collapse to a constant value of approximately 315 kWh. This is a known artefact of the generating process and is undesirable.

Another systematic effect arises from curtailment. At certain times, producers are paid to reduce generation due to market or transmission constraints, leading to artificially low production values. Prior work removed such periods, as they are not representative of unconstrained physical generation. In contrast, we retain these periods, as they reflect real‑world operational conditions.

\subsection{Data Cleaning}

Only light preprocessing of data was necessary:

\begin{itemize}
    \item Zero‑valued observations: Observations equal to exactly zero lead to numerical instability during the probability‑integral-transform stage of the pipeline. To avoid this, values of 0 were replaced with a small positive constant (0.01), which is practically indistinguishable at operational scales.
    \item Timestamp harmonization: he observational and ensemble datasets used slightly different timestamp formats. Both were converted to UTC to ensure alignment
\end{itemize} 

No additional filtering or smoothing was applied.

\subsection{Data Split}

We adopt a straightforward temporal train–test split, ensuring the test set corresponds to an uninterrupted future time interval.


Training set:
8437 time points (≈ 351 days)
spanning 2022‑01‑01 00:00 to 2022‑12‑13 04:00


Test set:
8106 time points (≈ 337.8 days)
spanning 2023‑10‑13 05:00 to 2024‑10‑12 23:00

The split ensures that the test period spans almost exactly one year, allowing evaluation across all seasons. This is important, as wind‑power production exhibits strong seasonal variability.

\subsection{Procedure}
Each zone is modeled independently, meaning:

\begin{itemize}
    \item one marginal quantile model per zone
    \item one correlation (SARIMA) model per zone
    \item no cross‑zone information is used
\end{itemize}


The marginal models use the ensemble forecast at the current time and up to lag 48 hours as covariates:

\[
X_t = [\mathbf{x}_t, x_{t-1},\dots, x_{t-48}]
\]

where $X_t \in \mathbb{R}^{51\times48}$ and $\mathbf{x}_t \in\mathbb{R}^{51} $

Only ensemble information is used as covariates; no observational data enters the forecast at prediction time. This mirrors operational conditions for ensemble‑based forecasting.

To prevent implicit leakage of information, we simulate long “burn‑in” periods in pseudo‑residual space, using a large forecasting horizon (h=10000) before extracting the final prediction window. This ensures predictions do not depend on information beyond the allowed horizon.

\subsection{Results}

Performance metrics for all zones and models are presented in \cref{tab:scores} (absolute scores) and \cref{tab:scores_percent} (scores normalized relative to the raw ensemble forecast).
\cref{fig:forecastexample} shows an example forecast produced using the latent marginal model. Notably, the illustrated period corresponds directly to the example data shown in \ref{casedata}.
\cref{loss} presents the training and validation loss curves for all marginal models. The simple model generally performs reasonably well, but struggles for DK2‑offshore—likely due to the ensemble collapse described earlier.
The estimated SARIMA parameters for all zones are given in \cref{tab:parameters}.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Results/Graphs/acf_pacf.pdf}
    \caption{Caption}
    \label{fig:forecastexample}
\end{figure}

\input{Results/Tables/parameters}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Results/Graphs/corrolation_example.pdf}
    \caption{Caption}
    \label{fig:forecastexample}
\end{figure}

\input{Results/Tables/scores}
