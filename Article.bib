@article{bjerreg2021a,
  title = {An Introduction to Multivariate Probabilistic Forecast Evaluation},
  author = {Bjerregård, Mathias Blicher and Møller, Jan Kloppenborg and Madsen, Henrik},
  date = {2021},
  journaltitle = {Energy and Ai},
  volume = {4},
  pages = {100058},
  publisher = {Elsevier},
  issn = {26665468},
  doi = {10.1016/j.egyai.2021.100058},
  abstract = {Probabilistic forecasting is becoming increasingly important for a wide range of applications, especially for energy systems such as forecasting wind power production. A need for proper evaluation of probabilistic forecasts follows naturally with this, because evaluation is the key to improving the forecasts. Although plenty of excellent reviews and research papers on probabilistic forecast evaluation already exist, we find that there is a need for an introduction with some practical application. In particular, many forecast scenarios in energy systems are inherently multivariate, and while univariate evaluation methods are well understood and documented, only limited and scattered work has been done on their multivariate counterparts. This paper therefore contains a review of a selected set of probabilistic forecast evaluation methods, primarily scoring rules, as well as practical sections that explain how these methods can be calculated and estimated. In three case studies featuring simple autoregressive models, stochastic differential equations and real wind power data, we implement, apply and discuss the logarithmic score, the continuous ranked probability score and the variogram score for forecasting problems of varying dimension. Finally, the advantages and disadvantages of the three scoring rules are highlighted, and this provides a significant step towards deciding on an evaluation method for a given multivariate forecast scenario including forecast scenarios relevant for energy systems.},
  langid = {english}
}

@article{gneiting2007a,
  title = {Strictly Proper Scoring Rules, Prediction, and Estimation},
  author = {Gneiting, Tilmann and Raftery, Adrian E},
  date = {2007},
  journaltitle = {Journal of the American Statistical Association},
  volume = {102},
  number = {477},
  pages = {359--378},
  publisher = {American Statistical Association},
  issn = {1537274x, 01621459},
  doi = {10.1198/016214506000001437},
  abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distribution F if he or she issues the probabilistic forecast F, rather than G ≠ F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples therof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed. We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
  langid = {english}
}

@article{HKSG02,
  title = {A State Space Framework for Automatic Forecasting Using Exponential Smoothing Methods},
  author = {Hyndman, Rob J and Koehler, Anne B and Snyder, Ralph D and Grose, Simone},
  date = {2002},
  journaltitle = {International Journal of Forecasting},
  volume = {18},
  number = {3},
  pages = {439--454}
}

@article{jorgensenSequentialMethodsError2025,
  title = {Sequential Methods for Error Correction of Probabilistic Wind Power Forecasts},
  author = {Jørgensen, Bastian Schmidt and Møller, Jan Kloppenborg and Nystrup, Peter and Madsen, Henrik},
  date = {2025},
  journaltitle = {Expert Systems With Applications},
  volume = {284},
  pages = {127872},
  publisher = {Pergamon},
  issn = {18736793, 09574174},
  doi = {10.1016/j.eswa.2025.127872},
  langid = {english}
}

@article{schmidhuber2015a,
  title = {Deep Learning in Neural Networks: An Overview},
  author = {Schmidhuber, Jürgen},
  date = {2015},
  journaltitle = {Neural Networks},
  volume = {61},
  pages = {85--117},
  publisher = {Cornell University},
  issn = {18792782, 08936080},
  doi = {10.1016/j.neunet.2014.09.003},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  langid = {english}
}

@misc{energinet_electricityprodex5min_2020,
  title        = {Electricity Production and Exchange – 5 Minute Realtime},
  author       = {{Energinet}},
  howpublished = {\url{https://www.energidataservice.dk/dataset/electricityprodex5minrealtime}},
  note         = {Dataset by TSO Electricity, CC BY 4.0 license},
  year         = {2020},
  publisher    = {Energi Data Service},
  url          = {https://www.energidataservice.dk/dataset/electricityprodex5minrealtime},
  urldate      = {2026-01-28}
}


@misc{energinet_production_consumption_settlement_2020,
  title        = {Production and Consumption -- Settlement},
  author       = {{Energinet}},
  howpublished = {\url{https://www.energidataservice.dk/dataset/productionconsumptionsettlement}},
  note         = {Dataset by TSO Electricity, CC BY 4.0 license},
  year         = {2020},
  publisher    = {Energi Data Service},
  url          = {https://www.energidataservice.dk/dataset/productionconsumptionsettlement},
  urldate      = {2026-01-28}
}

@online{ECMWF2025,
  type = {Text},
  title = {{{ECMWF}}},
  date = {2025-05-27},
  url = {https://www.ecmwf.int/},
  urldate = {2025-05-27},
  abstract = {Advancing global NWP through international collaboration},
  langid = {english},
  organization = {ECMWF},
  file = {C:\Users\kpfs\Zotero\storage\GUMA7SB9\www.ecmwf.int.html}
}

@misc{ecmwf_about_forecasts,
  title        = {About Our Forecasts},
  author       = {{European Centre for Medium-Range Weather Forecasts (ECMWF)}},
  howpublished = {\url{https://www.ecmwf.int/en/forecasts/about-forecasts}},
  note         = {Accessed on 2026-01-28},
  year         = {2025},
  publisher    = {ECMWF},
  url          = {https://www.ecmwf.int/en/forecasts/about-forecasts}
}

@article{olson2014a,
  author = {Olson, Arne and Jones, Ryan A. and Hart, Elaine and Hargreaves, Jeremy},
  abstract = {Controlled curtailment of variable energy resources can play a valuable role in meeting power system flexibility needs in California. Prospective VER curtailment is shown to reduce the occurrence of unserved energy due to lack of power system flexibility. VER curtailment can serve as a 'default' solution against which to measure the benefits of investment in flexible resources.},
  title = {Renewable Curtailment as a Power System Flexibility Resource},
  language = {eng},
  format = {article},
  journal = {Electricity Journal},
  volume = {27},
  number = {9},
  pages = {49-61},
  year = {2014},
  issn = {18736874, 10406190},
  publisher = {Elsevier Inc.},
  doi = {10.1016/j.tej.2014.10.005}
}

@book{theodoridis2020a,
  author = {Theodoridis, Sergios},
  abstract = {Machine Learning: A Bayesian and Optimization Perspective, 2nd edition, gives a unified perspective on machine learning by covering both pillars of supervised learning, namely regression and classification. The book starts with the basics, including mean square, least squares and maximum likelihood methods, ridge regression, Bayesian decision theory classification, logistic regression, and decision trees. It then progresses to more recent techniques, covering sparse modelling methods, learning in reproducing kernel Hilbert spaces and support vector machines, Bayesian inference with a focus on the EM algorithm and its approximate inference variational versions, Monte Carlo methods, probabilistic graphical models focusing on Bayesian networks, hidden Markov models and particle filtering. Dimensionality reduction and latent variables modelling are also considered in depth. This palette of techniques concludes with an extended chapter on neural networks and deep learning architectures. The book also covers the fundamentals of statistical parameter estimation, Wiener and Kalman filtering, convexity and convex optimization, including a chapter on stochastic approximation and the gradient descent family of algorithms, presenting related online learning techniques as well as concepts and algorithmic versions for distributed optimization. Focusing on the physical reasoning behind the mathematics, without sacrificing rigor, all the various methods and techniques are explained in depth, supported by examples and problems, giving an invaluable resource to the student and researcher for understanding and applying machine learning concepts. Most of the chapters include typical case studies and computer exercises, both in MATLAB and Python. The chapters are written to be as self-contained as possible, making the text suitable for different courses: pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as courses on sparse modeling, deep learning, and probabilistic graphical models. New to this edition: Complete re-write of the chapter on Neural Networks and Deep Learning to reflect the latest advances since the 1st edition. The chapter, starting from the basic perceptron and feed-forward neural networks concepts, now presents an in depth treatment of deep networks, including recent optimization algorithms, batch normalization, regularization techniques such as the dropout method, convolutional neural networks, recurrent neural networks, attention mechanisms, adversarial examples and training, capsule networks and generative architectures, such as restricted Boltzman machines (RBMs), variational autoencoders and generative adversarial networks (GANs). Expanded treatment of Bayesian learning to include nonparametric Bayesian methods, with a focus on the Chinese restaurant and the Indian buffet processes.},
  title = {Machine Learning: A Bayesian and Optimization Perspective, Second Edition},
  language = {eng},
  format = {book},
  journal = {Machine Learning: a Bayesian and Optimization Perspective, Second Edition},
  pages = {1-1131},
  year = {2020},
  isbn = {0128188030, 0128188049, 9780128188033, 9780128188040},
  publisher = {Elsevier},
  doi = {10.1016/C2019-0-03772-7}
}

@other{wan2012a,
  author = {Wan, Yih H.},
  abstract = {The National Renewable Energy Laboratory started collecting wind power data from large commercial wind power plants (WPPs) in southwest Minnesota with dedicated dataloggers and communication links in the spring of 2000. Over the years, additional WPPs in other areas were added to and removed from the data collection effort. The longest data stream of actual wind plant output is more than 10 years. The resulting data have been used to analyze wind power fluctuations, frequency distribution of changes, the effects of spatial diversity, and wind power ancillary services. This report uses the multi-year wind power data to examine long-term wind power variability.},
  title = {Long-Term Wind Power Variability},
  language = {und},
  format = {other},
  journal = {Osti Oai (u.s. Department of Energy Office of Scientific and Technical Information)},
  year = {2012},
  publisher = {Office of Scientific and Technical Information (OSTI)},
  doi = {10.2172/1033036}
}

@online{energinetEnergiDataService,
  title = {Energi {{Data Service}}},
  author = {Energinet},
  url = {https://www.energidataservice.dk/},
  urldate = {2025-06-07},
  abstract = {Open energy data from Energinet to society},
  langid = {english},
  organization = {Energinet},
  file = {C:\Users\kpfs\Zotero\storage\IHYWV5CV\www.energidataservice.dk.html}
}